#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import os
import errno
import shutil
import re
import fnmatch
import pdb
import numpy as np
import csv
from natsort import natsorted
from collections import namedtuple
import pysndfile
from pysndfile import PySndfile
import matplotlib.pyplot as plt

from pathops import dir_must_exist
from signalops import rolling_window_lastaxis, block_lfilter

import scipy.signal as sgnl
from scipy.stats import pearsonr

from pyswarm import pso

try:
    from lpc import lpc
except ImportError:
    from .lpc import lpc

try:
    from filesystem import globDir, organiseWavs, prepareOutDir
except ImportError:
    from .filesystem import globDir, organiseWavs, prepareOutDir


def synthesizeTrial(wavFileMatrix, indexes):
    '''
    Using the matrix of alternative words and the selected words for each
    column, generate samples from audio files
    Returns an array of samples generated by concatenating the selected audio
    files
    '''
    columnNames = ['a', 'b', 'c', 'd', 'e']
    indexes = np.pad(indexes, ((0, 1)), 'constant', constant_values=0)
    indexes = rolling_window_lastaxis(indexes, 2)
    offset = 10
    y = np.array([])
    filenames = []
    for name, ind in zip(columnNames, indexes):
        if name == 'e':
            offset = 1
        wavFilename, wavFilepath = wavFileMatrix[name][(ind[0]*offset)+ind[1]]
        wav = PySndfile(wavFilepath)
        fs = wav.samplerate()
        x = wav.read_frames()
        y = np.append(y, x)
        filenames.append(wavFilename)
    return (y, {'rate': fs, 'format': wav.major_format_str(), 'enc': wav.encoding_str()}, filenames)


def generateTrialInds(n=1):
    '''
    Generate array of shape (n, 5), with each column representing the columns
    of the matrix (a-e)
    Indexes are generated randomly without replacement, ensuring no duplicate
    identical samples are generated
    '''
    choice = np.random.choice(100000, n, replace=False)
    indexes = np.zeros((n, 5), dtype=int)
    for ind, c in enumerate(choice):
        indexes[ind] = [int(i) for i in str(c).zfill(5)]
    return indexes


def generateAudioStimulus(MatrixDir, OutDir, Length, socketio=None):
    # Get matrix wav file paths
    wavFiles = globDir(MatrixDir, '*.wav')
    wavFileMatrix = organiseWavs(wavFiles)
    # Randomly generate word choices for each trial
    indexes = generateTrialInds(100000)
    with open(os.path.join(OutDir, 'stim_parts.csv'), 'w') as csvfile:
        partwriter = csv.writer(csvfile)
        # Synthesize audio for each trial using generated word choices
        l = 0
        n = 0
        files = []
        while l < Length:
            if socketio:
                percent = (l / Length)*100.
                socketio.emit('update-progress', {'data': '{}%'.format(percent)}, namespace='/main')
            #print("Generating Trial_{0:05d}".format(n))
            y, wavInfo, partnames = synthesizeTrial(wavFileMatrix, indexes[n, :])
            partwriter.writerow(partnames)
            fileName = os.path.join(OutDir, 'Trial_{0:05d}.wav'.format(n))
            pysndfile.sndio.write(fileName, y, **wavInfo)
            n += 1
            l += y.size / wavInfo['rate']
            files.append(fileName)
    return files


def processNoise(x, order=500, plot=False, fs=None):
    '''
    Generate speech shaped noise from input signal x.
    Linear Predictive Coding is used to estimate and FIR filter of the order
    specified. This is then used to filter white noise.
    '''
    print("Calculating filter coefficients")
    x_fit = x[:fs*60*2]
    # Calculate filter coefficients using 2 minutes of speech
    b, a, e, k = calcLPC(x_fit, order, fs)
    # Generate and filter noise using calculted filter coefficients
    y = generateNoise(b, a, x.size, e, fs)
    # Calculate AIC of fitted filter
    #AIC = calcAIC(x, y, fs)
    if plot:
        plotLPC(x, y, fs)

    return y

def calcLPC(x, order, fs):
    a, e, k = lpc(x, order=order)
    b = np.zeros(a.size)
    b[0] = 1
    return b, a, e, k

def generateNoise(b, a, size, e, fs):
    print("Filtering white noise")
    noise = np.random.randn(size)*np.sqrt(e)
    y = block_lfilter(b, a, noise)
    return y


def calcAIC(x, y, fs):
    M=fs/10;
    f, Px_den = sgnl.welch(x,window='hamming', nperseg=M, nfft=M)
    f, Py_den = sgnl.welch(y,window='hamming', nperseg=M, nfft=M)
    resid = Px_den - Py_den
    sse = sum(resid**2)
    AIC= 2*order - 2*np.log(sse)
    return y, AIC


def plotLPC(x, y, fs):
    print("Plotting spectrum of the first 2 minutes of signal...")
    M=fs/10;
    f, Px_den = sgnl.welch(x[:fs*60*2],window='hamming', nperseg=M, nfft=M)
    f, Py_den = sgnl.welch(y[:fs*60*2],window='hamming', nperseg=M, nfft=M)
    plt.semilogy(f, Px_den)
    plt.semilogy(f, Py_den)
    #plt.ylim([0.5e-3, 1])
    plt.xlabel('frequency [Hz]')
    plt.ylabel('PSD [V**2/Hz]')
    plt.show()


def __calcLPCChunksPSOWrapper(params, *args):
    x = args[0]
    fs = args[1]
    length = args[2]
    order = int(round(params[0]))
    return calcLPCChunks(x, fs, plot=False, socketio=None, order=order, length=length)

def calcLPCChunks(x, fs, plot=False, socketio=None, order=500, length=1):
    # Define array of lengths in minutes to test
    length *= (fs * 60)
    length = int(length)
    chunkCount = 5
    start = ((np.arange(chunkCount)/chunkCount)*x.size).astype(int)
    end = length + start

    res = np.zeros(chunkCount)
    for j in range(start.size):
        print("Chunk: {0}".format(j))
        s = start[j]
        e = end[j]

        x_chunk = x[s:e]
        print("Chunk size: {0}".format((e-s)/fs))
        print("Order: {0}".format(order))
        y, aic = calcLPC(x_chunk, order, fs)
        res[j] = aic
    return np.mean(res)


def generateNoiseFromSentences(SentenceDir, OutDir, order=500, plot=False, socketio=None):
    '''
    Fit speech shaped noise to all wav files found in SentenceDir. Output
    speech shaped noise of a length equal to the combined length of all found
    audio in SentenceDir to OutDir.
    '''
    wavFiles = globDir(SentenceDir, '*.wav')
    data = []
    for path in wavFiles:
        audio, fs, enc, fmt = pysndfile.sndio.read(path, return_format=True)
        data.append(audio)
    x = np.concatenate(data)

    y = processNoise(x, order=order, plot=plot, fs=fs)
    noiseFile = os.path.join(OutDir, 'SSN.wav')
    print("Writing file...")
    pysndfile.sndio.write(os.path.join(OutDir, 'SSN.wav'), y, rate=fs, format=fmt, enc=enc)
    return noiseFile


if __name__ == "__main__":
    from pathtype import PathType
    # Create commandline interface
    parser = argparse.ArgumentParser(description='Generate stimulus for '
                                     'training TRF decoder by concatenating '
                                     'matrix test materials')
    parser.add_argument('--MatrixDir', type=PathType(exists=True, type='dir'),
                        default='./speech_components',
                        help='Matrix test speech data location')
    parser.add_argument('--OutDir', type=PathType(exists=None, type='dir'),
                        default='./out_trials', help='Output directory')
    parser.add_argument('--Length', type=int, default=60,
                        help='Concatenated length of trials in seconds')
    args = {k:v for k,v in vars(parser.parse_args()).items() if v is not None}

    if os.path.exists(args['OutDir']):
        shutil.rmtree(args['OutDir'])
        os.makedirs(args['OutDir'])
    # Generate output directory if it doesn't exist
    prepareOutDir(args['OutDir'])


    # Generate audio stimulus from arguments provided on command line
    generateAudioStimulus(**args)

    # Check directory for storing generated noise exists
    noiseDir = os.path.join(args['OutDir'], 'noise')
    dir_must_exist(noiseDir)

    generateNoiseFromSentences(args['OutDir'], noiseDir)


    '''
    wavFiles = globDir(args["OutDir"], '*.wav')
    data = []
    for path in wavFiles:
        audio, fs, enc, fmt = pysndfile.sndio.read(path, return_format=True)
        data.append(audio)
    x = np.concatenate(data)

    args = [x, fs, 0.05]
    lb = [1]
    ub = [1000]
    xopt, fopt = pso(__calcLPCChunksPSOWrapper, lb, ub, args=args)
    pdb.set_trace()
    '''
