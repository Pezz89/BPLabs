#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import os
import errno
import shutil
import re
import fnmatch
import pdb
import numpy as np
import csv
from natsort import natsorted
from collections import namedtuple
from pysndfile import PySndfile, sndio
import matplotlib.pyplot as plt

from pathops import dir_must_exist
try:
    from signalops import rolling_window_lastaxis, calc_rms
except ImportError:
    from .signalops import rolling_window_lastaxis, block_lfilter, calc_rms

import scipy.signal as sgnl
from scipy.stats import pearsonr

from pyswarm import pso

try:
    from lpc import lpc
except ImportError:
    from .lpc import lpc

try:
    from filesystem import globDir, organiseWavs, prepareOutDir
except ImportError:
    from .filesystem import globDir, organiseWavs, prepareOutDir


def block_lfilter_wav(b, a, x, outfile, fmt, fs, blocksize=8192):
    '''
    Filter 1D signal in blocks. For use with large signals
    '''
    new_state = np.zeros(b.size-1)
    sndfile = PySndfile(outfile, 'w', fmt, 1, fs)
    i = 0
    while i < x.size:
        print("Filtering {0} to {1} of {2}".format(i, i+blocksize, x.size))
        if i+blocksize > x.size:
            y, new_state = sgnl.lfilter(b,a,x[i:-1], zi=new_state)
            sndfile.write_frames(y)
        else:
            y, new_state = sgnl.lfilter(b,a,x[i:i+blocksize], zi=new_state)
            sndfile.write_frames(y)
        i += blocksize
    return sndfile


def synthesize_trial(wavFileMatrix, indexes):
    '''
    Using the matrix of alternative words and the selected words for each
    column, generate samples from audio files
    Returns an array of samples generated by concatenating the selected audio
    files
    '''
    columnNames = ['a', 'b', 'c', 'd', 'e']
    indexes = np.pad(indexes, ((0, 1)), 'constant', constant_values=0)
    indexes = rolling_window_lastaxis(indexes, 2)
    offset = 10
    y = np.array([])
    filenames = []
    for name, ind in zip(columnNames, indexes):
        if name == 'e':
            offset = 1
        wavFilename, wavFilepath = wavFileMatrix[name][(ind[0]*offset)+ind[1]]
        wav = PySndfile(wavFilepath)
        fs = wav.samplerate()
        x = wav.read_frames()
        y = np.append(y, x)
        filenames.append(wavFilename)
    return (y, {'rate': fs, 'format': wav.major_format_str(), 'enc': wav.encoding_str()}, filenames)


def gen_audio_stim(MatrixDir, OutDir, indexes):
    if os.path.exists(OutDir):
        shutil.rmtree(OutDir)
        os.makedirs(OutDir)
    wavFiles = globDir(MatrixDir, '*.wav')
    wavFileMatrix = organiseWavs(wavFiles)
    files = []
    n = 0
    o = 0
    for sentenceList in indexes:
        n += 1
        o = 0
        files.append([])
        for ind in sentenceList:
            o += 1
            y, wavInfo, partnames = synthesize_trial(wavFileMatrix, ind)
            fileName = os.path.join(OutDir, 'Trial_{0:02d}_{1:02d}.wav'.format(n, o))
            print("Generating: " + fileName)
            sndio.write(fileName, y, **wavInfo)
            files[-1].append(fileName)

    return files

def gen_indexes():
    x = np.repeat(np.arange(10), 5)
    x = x.reshape(10, 5)

    y = np.zeros((50, 10, 5), dtype=int)

    # 50 lists
    for i in range(50):
        x[:, 1] = np.roll(x[:, 1], 1)
        x[:, 2] = np.roll(x[:, 2], 2)
        x[:, 3] = np.roll(x[:, 3], 3)
        x[:, 4] = np.roll(x[:, 4], 4)
        y[i] = x.copy()
    return y

def gen_rms(files):
    rmsFiles = []
    for sentenceList in files:
        for file in sentenceList:
            head, tail = os.path.split(file)
            tail = os.path.splitext(tail)[0]
            tail = tail + "_rms.npy"
            head = os.path.join(head, "rms")
            dir_must_exist(head)
            rmsFilepath = os.path.join(head, tail)
            print("Generating: "+rmsFilepath)
            y, fs, _ = sndio.read(file)
            y_rms = calc_rms(y, round(0.02*fs))
            np.save(rmsFilepath, y_rms)
            rmsFiles.append(rmsFilepath)
    return rmsFiles

def detect_silences(rmsFiles, fs):
    silences = []
    for envelopeFile in rmsFiles:
        env = np.load(envelopeFile)
        silence = env < 0.001
        # Get segment start end indexes for all silences in envelope
        silentSegs = np.where(np.concatenate(([silence[0]],silence[:-1]!=silence[1:],[True])))[0].reshape(-1, 2)
        validSegs = np.diff(silentSegs) > 0.002*fs
        silences.append(silentSegs[np.repeat(validSegs, 2, axis=1)].reshape(-1, 2))
    return silences


def calc_spectrum(files, silences, fs=44100, plot=False):
    window = 4096
    sentenceLen = []
    sentenceFFT = []

    for ind, sentenceList in enumerate(files):
        for ind2, file in enumerate(sentenceList):
            x, fs, _ = sndio.read(file)
            f, t, Zxx = sgnl.stft(x, window=np.ones(window), nperseg=window, noverlap=0)
            sil = silences[ind*10+ind2]
            sTemp = np.zeros((sil.shape[0], t.size), dtype=bool)
            for ind3, s in enumerate(sil):
                sTemp[ind3, :] = np.logical_and(t > s[0], t < s[1])
            invalidFFT = np.any(sTemp, axis=0)
            sentenceFFT.append(np.mean(np.abs(Zxx[:, ~np.any(sTemp, axis=0)]), axis=1))
            sentenceLen.append(x.size)
    sentenceFFT = np.array(sentenceFFT)
    sentenceLen = np.array([sentenceLen]).T
    sentenceLen = sentenceLen / sentenceLen.max()
    grandAvgFFT = np.mean(sentenceFFT * sentenceLen, axis=0)
    print("Fitting filter...")
    b = sgnl.firls(2049, np.linspace(0, 1, 2049)[1:], grandAvgFFT[1:])
    if plot:
        plt.semilogy(np.abs(sgnl.freqz(b)[1]))
        plt.plot(np.linspace(0, 512, 2049), grandAvgFFT)
        plt.show()
    return b


def gen_noise(OutDir, b, fs):
    # Generate 10 minutes of white noise
    x = np.random.uniform(-1., 1., int(fs*60.*10.))
    noiseDir = os.path.join(OutDir, 'noise')
    dir_must_exist(noiseDir)
    y = block_lfilter_wav(b, [1.0], x, os.path.join(noiseDir, 'noise.wav'), 65538, 44100)
    return y


if __name__ == "__main__":
    from pathtype import PathType
    # Create commandline interface
    parser = argparse.ArgumentParser(description='Generate stimulus for '
                                     'training TRF decoder by concatenating '
                                     'matrix test materials')
    parser.add_argument('--MatrixDir', type=PathType(exists=True, type='dir'),
                        default='./speech_components',
                        help='Matrix test speech data location')
    parser.add_argument('--OutDir', type=PathType(exists=None, type='dir'),
                        default='./out_trials', help='Output directory')
    parser.add_argument('--SkipRMS', action='store_true')
    args = {k:v for k,v in vars(parser.parse_args()).items() if v is not None}

    if not args['SkipRMS']:
        indexes = gen_indexes()
        wavfiles = gen_audio_stim(args['MatrixDir'], args['OutDir'], indexes)
        rmsFiles = gen_rms(wavfiles)
    else:
        wavFiles = globDir(args['OutDir'], '*.wav')
        wf = []
        for listInd in range(50):
            wf.append([])
            for sentenceInd in range(10):
                wf[listInd].append(wavFiles[listInd*10+sentenceInd])
        wavFiles = wf

        rmsFiles = globDir(os.path.join(args['OutDir'], "rms"), '*.npy')
    silences = detect_silences(rmsFiles, 44100)
    b = calc_spectrum(wavFiles, silences)
    y = gen_noise(args['OutDir'], b, 44100)
